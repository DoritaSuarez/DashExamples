{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps, ImageChops, ImageFilter\n",
    "from numpy import asarray\n",
    "import os\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import cv2\n",
    "import functools \n",
    "from numba import vectorize, float64, int64\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2448, 3264)\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('Samsung.jpg')\n",
    "image_bw = image.convert(mode = \"L\") # Transform to black and white\n",
    "print(image_bw.size) # [0]: width in pixels [1]: height in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bite_params = (500, 600, 2300, 2200)\n",
    "guide_params = (30, 2400, 200, 2650)\n",
    "wedge_params = (1050, 2650, 1400, 2950)\n",
    "cut_params = [(150,1100),(220,820),(450.40,800),(400,1200.18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculo(image, bite_params, guide_params, wedge_params, cut_params):\n",
    "    image_bw = image.convert(mode = \"L\") # Transform to black and white\n",
    "    bite = np.array(image_bw.crop(bite_params))\n",
    "    guide = np.array(image_bw.crop(guide_params))\n",
    "    wedge = np.array(image_bw.crop(wedge_params))\n",
    "    \n",
    "    def change_contrast(img, level):\n",
    "        factor = (259 * (level + 255)) / (255 * (259 - level))\n",
    "        def contrast(c):\n",
    "            return 128 + factor * (c - 128)\n",
    "        return img.point(contrast)\n",
    "    \n",
    "    guide_cont = change_contrast(image, 100)\n",
    "    guide_cont = np.array(guide_cont.crop(guide_params))\n",
    "\n",
    "    guide_cont = cv2.cvtColor(guide_cont,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mid = round(guide_cont.shape[0]/2)\n",
    "    zeros = [i for i, e in enumerate(guide_cont[mid]) if e == 0]\n",
    "    \n",
    "    sum_t = 0\n",
    "    count = 0\n",
    "    pix = []\n",
    "    for i in range(len(zeros)-1):\n",
    "        if((zeros[i+1]-zeros[i]) == 1):\n",
    "            sum_t = sum_t + zeros[i]\n",
    "            count = count + 1\n",
    "        else:\n",
    "            pix.append(round(sum_t/count))\n",
    "            sum_t = 0\n",
    "            count = 0\n",
    "        \n",
    "    mm = round(np.mean(np.diff(pix)))\n",
    "    \n",
    "    wedge_w = []\n",
    "\n",
    "    for i in range(wedge.shape[0]):\n",
    "        x = list(wedge[i])\n",
    "        wedge_w.append(max(x))\n",
    "    pix_med_y = wedge_w.index(max(wedge_w))\n",
    "#     plt.imshow(wedge)\n",
    "    \n",
    "    pix_med_x = np.argmax(wedge[pix_med_y])\n",
    "    \n",
    "    dist = []\n",
    "    prof = []\n",
    "    dist_p = []\n",
    "    for i in range(wedge.shape[1]):\n",
    "            dist.append(np.abs(i - pix_med_x)/mm)\n",
    "            dist_p.append(np.abs(i - pix_med_x))\n",
    "            prof.append(wedge[pix_med_x][i])\n",
    "\n",
    "#     plt.plot(dist_p, prof)\n",
    "    data_wedge_dist = pd.DataFrame({\"d_pix\":prof, \"x_pix\":dist_p, \"x_mm\":dist})\n",
    "    \n",
    "    x = np.arange(-19, 19, 0.01)\n",
    "\n",
    "    def tomm(w):\n",
    "        return -np.sqrt(361-w*w) + 19\n",
    "    #     return -1/2*np.sqrt(22201-4*w*w)\n",
    "\n",
    "    y = list(map(tomm, x))\n",
    "    y_pix = list(map(lambda w: round(w*mm), y))\n",
    "    x_pix = list(map(lambda w: round(w*mm), x))\n",
    "\n",
    "    data_wedge_depth = pd.DataFrame({\"x_mill\":x, \"y_mill\":y, \"y_pix\":y_pix, \"x_pix\":x_pix})\n",
    "\n",
    "    wedge_dd = data_wedge_depth.merge(data_wedge_dist)\n",
    "    wedge_xd = wedge_dd.groupby(\"x_pix\").median().reset_index()\n",
    "    wedge_dd = wedge_dd.groupby(\"d_pix\").median().reset_index()\n",
    "    \n",
    "    k_pix = min(np.array(wedge_dd[wedge_dd.y_mill <= 0.05][\"d_pix\"]))\n",
    "    w_pix = min(np.array(wedge_dd[wedge_dd.y_mill <= 0.35][\"d_pix\"]))\n",
    "    \n",
    "    def depth_found(dist, a):\n",
    "        y =  [i for i, e in enumerate(prof) if e == a]\n",
    "        if(len(y)== 0):\n",
    "            return \"not found\"\n",
    "        else:\n",
    "            return np.median([dist[i] for i in y])\n",
    "\n",
    "    distances = []\n",
    "    depths = []\n",
    "\n",
    "    for i in range(255):\n",
    "        distances.append(depth_found(dist, i))\n",
    "        depths.append(i)\n",
    "\n",
    "    for i in range(len(distances)):\n",
    "        if(i == 0 and distances[i]==\"not found\"):\n",
    "            aux = [x for x in distances if x!= \"not found\"]\n",
    "            distances[i] = max(aux)\n",
    "        if(distances[i] == \"not found\"):\n",
    "            distances[i] = distances[i - 1]\n",
    "    \n",
    "    \n",
    "    @vectorize([int64(float64)])\n",
    "    def redondear(x):\n",
    "        return x\n",
    "    \n",
    "    cut_params = redondear(cut_params)\n",
    "    pts = np.array(cut_params)\n",
    "    ## (1) Crop the bounding rect\n",
    "    rect = cv2.boundingRect(pts)\n",
    "    x,y,w,h = rect\n",
    "    croped = bite[y:y+h, x:x+w].copy()\n",
    "\n",
    "    ## (2) make mask\n",
    "    pts = pts - pts.min(axis=0)\n",
    "\n",
    "    mask = np.zeros(croped.shape[:2], np.uint8)\n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "    ## (3) do bit-op\n",
    "    dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
    "\n",
    "    ## (4) add the white background\n",
    "    bg = np.ones_like(croped, np.uint8)*255\n",
    "    # cv2.bitwise_not(bg,bg, mask=mask)\n",
    "#     plt.imshow(dst)\n",
    "    \n",
    "    class Switch(dict):\n",
    "        def __getitem__(self, item):\n",
    "            for key in self.keys():                   # iterate over the intervals\n",
    "                if item in key:                       # if the argument is part of that interval\n",
    "                    return super().__getitem__(key)   # return its associated value\n",
    "            raise KeyError(item)                      # if not in any interval, raise KeyError\n",
    "\n",
    "    switch = Switch({\n",
    "        range(k_pix, 255): 2,\n",
    "        range(w_pix, k_pix): 1,\n",
    "        range(0, w_pix): 0\n",
    "    })\n",
    "    \n",
    "    @vectorize([float64(float64)])\n",
    "    def f(x):\n",
    "        return switch[x]\n",
    "    \n",
    "    classification = f(dst)\n",
    "    \n",
    "    low = 0\n",
    "    contact = 0\n",
    "    close = 0\n",
    "    for i in range(classification.shape[0]):\n",
    "        for j in range(classification.shape[1]):\n",
    "                if(classification[i][j] == 0):\n",
    "                    low = low + 1\n",
    "                if(classification[i][j] == 1):\n",
    "                    close = close +1\n",
    "                if(classification[i][j] == 2):\n",
    "                    contact = contact +1\n",
    "    \n",
    "    area_contact = (1/mm**2)*contact\n",
    "    area_close = (1/mm**2)*close\n",
    "    \n",
    "    return area_contact, area_close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = calculo(image, bite_params, guide_params, wedge_params, cut_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6789940828402367, 2.75)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
